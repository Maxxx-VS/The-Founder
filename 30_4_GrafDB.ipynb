{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOUFcT3qlFDgBLMTRJLtWpu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5865f9b6f08a46a28e329d3b8532f29c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8bcf8a4ca31a47ce9c31dd9f5c26a1ca",
              "IPY_MODEL_0d82de664bea4c4cb2c93d452ea46a07",
              "IPY_MODEL_bfe4aa8ac651466a81772f1fdfcc943d"
            ],
            "layout": "IPY_MODEL_a287f7bb88024f9e9b6b58eced0a1874"
          }
        },
        "8bcf8a4ca31a47ce9c31dd9f5c26a1ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_426e4ed453a84b40bae7bd7435207612",
            "placeholder": "​",
            "style": "IPY_MODEL_e7fcb931291244389ad33723d03ef916",
            "value": "generation_config.json: 100%"
          }
        },
        "0d82de664bea4c4cb2c93d452ea46a07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef98b1b9335244fea21cb9e4e81298cc",
            "max": 265,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f6bea24949db40eea5022ee7f4b7af83",
            "value": 265
          }
        },
        "bfe4aa8ac651466a81772f1fdfcc943d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59fef69a21c845dd88d54c1fdef99c52",
            "placeholder": "​",
            "style": "IPY_MODEL_16d33f1f2b65463ba57d7951ea439ea0",
            "value": " 265/265 [00:00&lt;00:00, 16.8kB/s]"
          }
        },
        "a287f7bb88024f9e9b6b58eced0a1874": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "426e4ed453a84b40bae7bd7435207612": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7fcb931291244389ad33723d03ef916": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ef98b1b9335244fea21cb9e4e81298cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6bea24949db40eea5022ee7f4b7af83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "59fef69a21c845dd88d54c1fdef99c52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16d33f1f2b65463ba57d7951ea439ea0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Maxxx-VS/The-Founder/blob/master/30_4_GrafDB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "На 3 балла. Собрать интерфейс Gradio для модели из урока. В качестве данных выбрать любую статью или статьи из википедии. Должна быть кнопка распарсить данные и отправить запрос.\n",
        "\n",
        "На 4 балла. Изучите представленные Ридеры на Llama Hub. С помощью выбранного Ридера (любой кроме википедии) загрузите данные в графовую базу данных. И выполните первое заданий ДЗ с этим Ридером.\n",
        "\n",
        "На 5 баллов. Выполните первое задание. В качестве модели используйте любую русскоязычную модель от SberDevice. Изучите порядок загрузки модели (он изменится), как поменяется промпт и настройки модели."
      ],
      "metadata": {
        "id": "SaXYiPCMVBoZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": true,
        "id": "X1cazoyRU6Rl"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install git+https://github.com/huggingface/transformers\n",
        "!pip install llama_index pyvis Ipython langchain pypdf langchain_community\n",
        "!pip install llama-index-llms-huggingface\n",
        "!pip install llama-index-embeddings-huggingface\n",
        "!pip install llama-index-embeddings-langchain\n",
        "!pip install langchain-huggingface\n",
        "!pip install sentencepiece accelerate\n",
        "!pip install -U bitsandbytes\n",
        "!pip install peft\n",
        "!pip install llama-index-readers-wikipedia wikipedia\n",
        "!pip install openai gradio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "from llama_index.core import SimpleDirectoryReader\n",
        "from llama_index.core import KnowledgeGraphIndex\n",
        "from llama_index.core import Settings\n",
        "from llama_index.core.graph_stores import SimpleGraphStore\n",
        "from llama_index.core import StorageContext\n",
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "from llama_index.llms.huggingface import HuggingFaceLLM\n",
        "from llama_index.embeddings.langchain import LangchainEmbedding\n",
        "from llama_index.core.prompts import PromptTemplate\n",
        "from llama_index.readers.wikipedia import WikipediaReader\n",
        "\n",
        "from peft import PeftModel, PeftConfig\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, GenerationConfig, BitsAndBytesConfig\n",
        "import torch\n",
        "import gradio as gr\n",
        "\n",
        "from langchain_huggingface  import HuggingFaceEmbeddings\n",
        "from huggingface_hub import login\n",
        "HF_TOKEN=\"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\"\n",
        "login(HF_TOKEN, add_to_git_credential=True)"
      ],
      "metadata": {
        "id": "RqoHCvu6VpOS"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def messages_to_prompt(messages):\n",
        "    prompt = \"\"\n",
        "    for message in messages:\n",
        "        if message.role == 'system':\n",
        "            prompt += f\"<s>{message.role}\\n{message.content}</s>\\n\"\n",
        "        elif message.role == 'user':\n",
        "            prompt += f\"<s>{message.role}\\n{message.content}</s>\\n\"\n",
        "        elif message.role == 'bot':\n",
        "            prompt += f\"<s>bot\\n\"\n",
        "\n",
        "    if not prompt.startswith(\"<s>system\\n\"):\n",
        "        prompt = \"<s>system\\n</s>\\n\" + prompt\n",
        "\n",
        "    prompt = prompt + \"<s>bot\\n\"\n",
        "    return prompt\n",
        "\n",
        "def completion_to_prompt(completion):\n",
        "    return f\"<s>system\\n</s>\\n<s>user\\n{completion}</s>\\n<s>bot\\n\""
      ],
      "metadata": {
        "id": "JovCoDjkY_Qz"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "quantization_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_use_double_quant=True,)\n",
        "\n",
        "MODEL_NAME = \"IlyaGusev/saiga_mistral_7b\"\n",
        "\n",
        "config = PeftConfig.from_pretrained(MODEL_NAME)\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    config.base_model_name_or_path,          # идентификатор модели\n",
        "    quantization_config=quantization_config, # параметры квантования\n",
        "    torch_dtype=torch.float16,               # тип данных\n",
        "    device_map=\"auto\")                        # автоматический выбор типа устройства\n",
        "\n",
        "model = PeftModel.from_pretrained(model, MODEL_NAME, torch_dtype=torch.float16)\n",
        "model.eval()\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=False)"
      ],
      "metadata": {
        "id": "NuVePlexZUso"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generation_config = GenerationConfig.from_pretrained(MODEL_NAME)\n",
        "# print(generation_config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "5865f9b6f08a46a28e329d3b8532f29c",
            "8bcf8a4ca31a47ce9c31dd9f5c26a1ca",
            "0d82de664bea4c4cb2c93d452ea46a07",
            "bfe4aa8ac651466a81772f1fdfcc943d",
            "a287f7bb88024f9e9b6b58eced0a1874",
            "426e4ed453a84b40bae7bd7435207612",
            "e7fcb931291244389ad33723d03ef916",
            "ef98b1b9335244fea21cb9e4e81298cc",
            "f6bea24949db40eea5022ee7f4b7af83",
            "59fef69a21c845dd88d54c1fdef99c52",
            "16d33f1f2b65463ba57d7951ea439ea0"
          ]
        },
        "id": "QbJHgoDIb_i8",
        "outputId": "7f91b66c-a957-47bd-89c8-0408fdb67932"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/265 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5865f9b6f08a46a28e329d3b8532f29c"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm = HuggingFaceLLM(\n",
        "    model=model,             # модель\n",
        "    model_name=MODEL_NAME,   # идентификатор модели\n",
        "    tokenizer=tokenizer,     # токенизатор\n",
        "    max_new_tokens=generation_config.max_new_tokens, # параметр необходимо использовать здесь, и не использовать в generate_kwargs, иначе ошибка двойного использования\n",
        "    model_kwargs={\"quantization_config\": quantization_config}, # параметры квантования\n",
        "    generate_kwargs = {   # параметры для инференса\n",
        "      \"bos_token_id\": generation_config.bos_token_id, # токен начала последовательности\n",
        "      \"eos_token_id\": generation_config.eos_token_id, # токен окончания последовательности\n",
        "      \"pad_token_id\": generation_config.pad_token_id, # токен пакетной обработки (указывает, что последовательность ещё не завершена)\n",
        "      \"no_repeat_ngram_size\": generation_config.no_repeat_ngram_size,\n",
        "      \"repetition_penalty\": generation_config.repetition_penalty,\n",
        "      \"temperature\": generation_config.temperature,\n",
        "      \"do_sample\": True,\n",
        "      \"top_k\": 50,\n",
        "      \"top_p\": 0.95},\n",
        "\n",
        "    messages_to_prompt=messages_to_prompt,     # функция для преобразования сообщений к внутреннему формату\n",
        "    completion_to_prompt=completion_to_prompt, # функции для генерации текста\n",
        "    device_map=\"auto\",)                         # автоматически определять устройство"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4g3Ut5cmZaEt",
        "outputId": "8272704d-2259-40af-ba1d-c6c2450d0dcd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:llama_index.llms.huggingface.base:The model `Open-Orca/Mistral-7B-OpenOrca` and tokenizer `IlyaGusev/saiga_mistral_7b` are different, please ensure that they are compatible.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Инициализация объекта WikipediaReader\n",
        "reader = WikipediaReader()\n",
        "\n",
        "# Загрузка данных из википедии\n",
        "docs = reader.load_data(\n",
        "    pages=[\"Медицина\"],  # запрос раздела на тему Медицина\n",
        "    lang_prefix = 'ru')  # из рускозычной зоны википедии"
      ],
      "metadata": {
        "id": "ciwF_Gn7ZtbP"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "embed_model = LangchainEmbedding(\n",
        "  HuggingFaceEmbeddings(model_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"))"
      ],
      "metadata": {
        "id": "x_N-_mlxZwFK"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "Settings.llm = llm\n",
        "Settings.embed_model = embed_model\n",
        "Settings.chunk_size = 512\n",
        "graph_store = SimpleGraphStore()\n",
        "storage_context = StorageContext.from_defaults(graph_store=graph_store)\n",
        "indexKG = KnowledgeGraphIndex.from_documents(documents=docs,               # данные для построения графов\n",
        "                                           max_triplets_per_chunk=3,        # сколько обработывать триплетов связей для каждого блока данных\n",
        "                                           show_progress=True,              # показывать процесс выполнения\n",
        "                                           include_embeddings=True,         # включение векторных вложений в индекс для расширенной аналитики\n",
        "                                           storage_context=storage_context) # куда сохранять результаты"
      ],
      "metadata": {
        "id": "xvcv6_AIZysa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def greet(theme):\n",
        "    query = f\"Расскажи о {theme} консультантах. Как они могут помочь мне?\"\n",
        "    query_engine = indexKG.as_query_engine(include_text=True, verbose=True)\n",
        "    message_template = f\"\"\"<s>system\n",
        "                          Отвечай в соответствии с Источником. Проверь,\n",
        "                          есть ли в Источнике упоминания о ключевых словах Вопроса.\n",
        "                          Если нет, то просто скажи: 'я не знаю'. Не придумывай! </s>\n",
        "                          <s>user\n",
        "                          Вопрос: {query}\n",
        "                          Источник: </s>\"\"\"\n",
        "    response = query_engine.query(message_template)\n",
        "\n",
        "    return response.response\n",
        "\n",
        "# создание интерфейса к функции\n",
        "demo = gr.Interface(\n",
        "    fn=greet,\n",
        "    inputs=[gr.Textbox(label=\"Запрос\", lines=1)],\n",
        "    outputs=[gr.Textbox(label=\"Выходные данные\", lines=1)],\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "demo.launch(share=True)"
      ],
      "metadata": {
        "id": "pUctUYK-Yyis"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# query = \"Расскажи о медицинский роботах консультантах. Как они могут улучшить мое состояние?\"\n",
        "# query_engine = indexKG.as_query_engine(include_text=True, verbose=True)\n",
        "\n",
        "# message_template =f\"\"\"<s>system\n",
        "# Отвечай в соответствии с Источником. Проверь, есть ли в Источнике упоминания о ключевых словах Вопроса.\n",
        "# Если нет, то просто скажи: 'я не знаю'. Не придумывай! </s>\n",
        "# <s>user\n",
        "# Вопрос: {query}\n",
        "# Источник:\n",
        "# </s>\n",
        "# \"\"\"\n",
        "# response = query_engine.query(message_template)\n",
        "\n",
        "# print(f'Ответ: {response.response}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXm9nlB6Z5KU",
        "outputId": "abf462f7-2289-4302-ebf7-ed6acca8bb9c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;3;32mExtracted keywords: ['консультанты', 'медицинские', 'состояние', 'улучшить', 'роботы']\n",
            "\u001b[0m\u001b[1;3;34mKG context:\n",
            "The following are knowledge sequence in max depth 2 in the form of directed graph like:\n",
            "`subject -[predicate]->, object, <-[predicate_next_hop]-, object_next_hop ...`\n",
            "('Знание биостатистики', 'Важное значение', 'Планированию медицинских исследований')\n",
            "('Лекарственный делом', 'Занимались', 'Врачи-эмпирики')\n",
            "\u001b[0mОтвет: Конечно, я могу помочь вам с этим! Медицинские роботы являются новым подходом к предоставлению медицинских услуг, который использует технологии искусственного интеллекта для диагностики, лечения и консультаций. Они могут быть особенно полезными для тех, кто живет в удаленных районах или странах, где доступ к традиционным медицинским услугам может быть ограничен.\n",
            "\n",
            "Медицинские роботы могут помочь вам улучшить свое состояние, предоставляя следующие услуги:\n",
            "\n",
            "1. Диагностика: Роботы могут использовать различные методы диагностики, такие как рентгенография, магнитно-резонансная томография, ультразвуковое исследование и многие другие. Это позволяет им выявить заболевания и проблемы, которые могут быть трудно заметить человеком.\n",
            "\n",
            "2. Лечение: Некоторые медицинские роботы могут даже применять лечение, например, в области хирургии. Роботы могут выполнять операции с высокой точностью и безопасностью, что может быть особенно важно для сложных процедур.\n",
            "\n",
            "3. Консультации: Роботы могут предоставлять консультации по медицинским вопросам, используя свои знания и опыт. Это может быть особенно полезно для тех, кто живет в удаленных районах, где доступ к традиционным медицинским консультациям может быть ограничен.\n",
            "\n",
            "4. Мониторинг: Роботы могут мониторить ваше состояние, контролировать ваши параметры и предупреждать о возможных проблемах. Это может быть особенно полезно в случаях, когда ваш доктор находится в другом городе или даже стране.\n",
            "\n",
            "5. Реабилитация: Роботы могут помочь вам восстановиться после проведения операции или лечения. Они могут предоставлять реабилитационные программы, которые помогут вам вернуться к нормальной жизни.\n",
            "\n",
            "Я надеюсь, что это поможет вам лучше понять, как медицинские роботы могут улучшить ваше состояние. Если у вас есть еще вопросы, не стесняйтесь задавать!\n"
          ]
        }
      ]
    }
  ]
}