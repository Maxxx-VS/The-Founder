{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMn+ya+S/5pj3SpiBiVJrsQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Maxxx-VS/The-Founder/blob/master/50_4_Speech_synthesis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "# Install dependencies with compatible versions\n",
        "!pip uninstall -y numpy torch torchaudio\n",
        "!pip install numpy==1.23.5\n",
        "!pip install torch==2.0.1 torchaudio==2.0.2 --extra-index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install transformers==4.30.2 speechbrain==0.5.15 gradio==3.41.2 sounddevice==0.4.6\n",
        "!pip install git+https://github.com/coqui-ai/TTS.git@v0.13.0\n",
        "!pip install pydub\n",
        "\n",
        "import os\n",
        "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"  # Resolves potential library conflicts\n",
        "\n",
        "import gradio as gr\n",
        "import torch\n",
        "import torchaudio\n",
        "import numpy as np\n",
        "import sounddevice as sd\n",
        "from queue import Queue\n",
        "import time\n",
        "import warnings\n",
        "from transformers import pipeline, AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "from TTS.api import TTS\n",
        "from speechbrain.pretrained import EncoderClassifier\n",
        "from pydub import AudioSegment\n",
        "from pydub.playback import play\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "class VoiceTranslator:\n",
        "    def __init__(self):\n",
        "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        print(f\"üöÄ Initializing on {self.device}...\")\n",
        "\n",
        "        # Initialize models\n",
        "        self.init_models()\n",
        "\n",
        "        # Audio settings\n",
        "        self.sample_rate = 16000\n",
        "        self.is_recording = False\n",
        "        self.audio_queue = Queue()\n",
        "\n",
        "    def init_models(self):\n",
        "        \"\"\"Initialize all required models\"\"\"\n",
        "        try:\n",
        "            print(\"üîä Loading speech recognition model...\")\n",
        "            self.asr = pipeline(\n",
        "                \"automatic-speech-recognition\",\n",
        "                model=\"openai/whisper-medium\",\n",
        "                device=self.device\n",
        "            )\n",
        "\n",
        "            print(\"üåç Loading translation models...\")\n",
        "            self.translators = {\n",
        "                ('en', 'ru'): self.load_translator(\"Helsinki-NLP/opus-mt-en-ru\"),\n",
        "                ('ru', 'en'): self.load_translator(\"Helsinki-NLP/opus-mt-ru-en\"),\n",
        "                ('de', 'en'): self.load_translator(\"Helsinki-NLP/opus-mt-de-en\"),\n",
        "                ('en', 'de'): self.load_translator(\"Helsinki-NLP/opus-mt-en-de\"),\n",
        "                ('de', 'ru'): self.load_translator(\"Helsinki-NLP/opus-mt-de-ru\"),\n",
        "                ('ru', 'de'): self.load_translator(\"Helsinki-NLP/opus-mt-ru-de\")\n",
        "            }\n",
        "\n",
        "            print(\"üéôÔ∏è Loading voice encoder...\")\n",
        "            self.voice_encoder = EncoderClassifier.from_hparams(\n",
        "                source=\"speechbrain/spkrec-ecapa-voxceleb\",\n",
        "                run_opts={\"device\": self.device},\n",
        "                savedir=\"tmp_voice_model\"\n",
        "            )\n",
        "\n",
        "            print(\"üó£Ô∏è Loading TTS with voice cloning...\")\n",
        "            self.tts = TTS(\n",
        "                model_name=\"tts_models/multilingual/multi-dataset/your_tts\",\n",
        "                progress_bar=False\n",
        "            ).to(self.device)\n",
        "\n",
        "            print(\"‚úÖ All models loaded successfully!\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Initialization failed: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def load_translator(self, model_name):\n",
        "        \"\"\"Helper to load translation model\"\"\"\n",
        "        model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(self.device)\n",
        "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "        return {'model': model, 'tokenizer': tokenizer}\n",
        "\n",
        "    def record_audio(self, duration=5):\n",
        "        \"\"\"Record audio from microphone\"\"\"\n",
        "        print(f\"‚è∫Ô∏è Recording {duration}s of audio...\")\n",
        "        self.is_recording = True\n",
        "        audio = []\n",
        "\n",
        "        def callback(indata, frames, time, status):\n",
        "            if self.is_recording:\n",
        "                audio.append(indata.copy())\n",
        "\n",
        "        try:\n",
        "            with sd.InputStream(\n",
        "                callback=callback,\n",
        "                channels=1,\n",
        "                samplerate=self.sample_rate,\n",
        "                dtype='float32'\n",
        "            ):\n",
        "                start_time = time.time()\n",
        "                while self.is_recording and (time.time() - start_time < duration):\n",
        "                    time.sleep(0.1)\n",
        "\n",
        "            return np.concatenate(audio) if audio else np.zeros(0)\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Recording error: {str(e)}\")\n",
        "            return np.zeros(0)\n",
        "\n",
        "    def recognize_speech(self, audio):\n",
        "        \"\"\"Convert speech to text\"\"\"\n",
        "        if len(audio) == 0:\n",
        "            return \"\"\n",
        "\n",
        "        print(\"üîç Recognizing speech...\")\n",
        "        try:\n",
        "            # Convert to mono if needed\n",
        "            if len(audio.shape) > 1:\n",
        "                audio = np.mean(audio, axis=1)\n",
        "\n",
        "            # Normalize audio\n",
        "            audio = audio / np.max(np.abs(audio))\n",
        "\n",
        "            # Recognize\n",
        "            result = self.asr(audio, generate_kwargs={\"language\": \"<detect>\"})\n",
        "            text = result[\"text\"]\n",
        "            print(f\"üí¨ Recognized: {text}\")\n",
        "            return text\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Recognition error: {str(e)}\")\n",
        "            return \"\"\n",
        "\n",
        "    def translate_text(self, text, source_lang, target_lang):\n",
        "        \"\"\"Translate text between languages\"\"\"\n",
        "        if not text or source_lang == target_lang:\n",
        "            return text\n",
        "\n",
        "        print(f\"üåê Translating {source_lang} ‚Üí {target_lang}...\")\n",
        "        try:\n",
        "            translator = self.translators.get((source_lang, target_lang))\n",
        "            if not translator:\n",
        "                return f\"[UNSUPPORTED TRANSLATION: {source_lang}‚Üí{target_lang}]\"\n",
        "\n",
        "            inputs = translator['tokenizer'](text, return_tensors=\"pt\").to(self.device)\n",
        "            translated_ids = translator['model'].generate(**inputs)\n",
        "            translated_text = translator['tokenizer'].decode(translated_ids[0], skip_special_tokens=True)\n",
        "            print(f\"‚úÖ Translated: {translated_text}\")\n",
        "            return translated_text\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Translation error: {str(e)}\")\n",
        "            return f\"[TRANSLATION ERROR]\"\n",
        "\n",
        "    def extract_voice_features(self, audio):\n",
        "        \"\"\"Extract speaker embeddings for voice cloning\"\"\"\n",
        "        if len(audio) == 0:\n",
        "            return None\n",
        "\n",
        "        print(\"üé§ Extracting voice features...\")\n",
        "        try:\n",
        "            audio_tensor = torch.from_numpy(audio).float().unsqueeze(0)\n",
        "            if audio_tensor.shape[0] > 1:\n",
        "                audio_tensor = torch.mean(audio_tensor, dim=0)\n",
        "            audio_tensor = audio_tensor / torch.max(torch.abs(audio_tensor))\n",
        "\n",
        "            with torch.no_grad():\n",
        "                embedding = self.voice_encoder.encode_batch(audio_tensor.to(self.device))\n",
        "\n",
        "            return embedding.squeeze(0).cpu().numpy()\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Voice feature extraction error: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def synthesize_speech(self, text, voice_features, target_lang):\n",
        "        \"\"\"Convert text to speech with voice cloning\"\"\"\n",
        "        if not text or voice_features is None:\n",
        "            return None\n",
        "\n",
        "        print(\"üîä Synthesizing speech...\")\n",
        "        try:\n",
        "            lang_code = {'en': 'en', 'ru': 'ru', 'de': 'de'}.get(target_lang, 'en')\n",
        "            speaker_embedding = torch.from_numpy(voice_features).unsqueeze(0).to(self.device)\n",
        "\n",
        "            wav = self.tts.tts_with_embeddings(\n",
        "                text=text,\n",
        "                speaker_embedding=speaker_embedding,\n",
        "                language=lang_code\n",
        "            )\n",
        "\n",
        "            return np.array(wav)\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Synthesis error: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def process_audio(self, source_lang, target_lang, duration):\n",
        "        \"\"\"Complete processing pipeline\"\"\"\n",
        "        try:\n",
        "            # 1. Record audio\n",
        "            audio = self.record_audio(duration)\n",
        "            if len(audio) == 0:\n",
        "                return \"No audio recorded\", \"\", None\n",
        "\n",
        "            # 2. Recognize speech\n",
        "            text = self.recognize_speech(audio)\n",
        "            if not text.strip():\n",
        "                return \"No speech detected\", \"\", None\n",
        "\n",
        "            # 3. Translate text\n",
        "            translated_text = self.translate_text(text, source_lang, target_lang)\n",
        "\n",
        "            # 4. Extract voice features\n",
        "            voice_features = self.extract_voice_features(audio)\n",
        "\n",
        "            # 5. Synthesize translated speech\n",
        "            translated_audio = self.synthesize_speech(translated_text, voice_features, target_lang)\n",
        "\n",
        "            if translated_audio is None:\n",
        "                return text, translated_text, None\n",
        "\n",
        "            return text, translated_text, (self.sample_rate, translated_audio)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Processing error: {str(e)}\")\n",
        "            return f\"Error: {str(e)}\", \"\", None\n",
        "\n",
        "    def stop_recording(self):\n",
        "        \"\"\"Stop the recording process\"\"\"\n",
        "        self.is_recording = False\n",
        "        return \"‚èπÔ∏è Recording stopped\"\n",
        "\n",
        "def create_interface():\n",
        "    translator = VoiceTranslator()\n",
        "\n",
        "    with gr.Blocks(title=\"Real-Time Voice Translator\") as demo:\n",
        "        gr.Markdown(\"\"\"\n",
        "        # üéôÔ∏è Real-Time Voice Translator\n",
        "        *Supports English ‚Üî Russian ‚Üî German with voice preservation*\n",
        "        \"\"\")\n",
        "\n",
        "        with gr.Row():\n",
        "            with gr.Column():\n",
        "                source_lang = gr.Dropdown(\n",
        "                    [\"en\", \"ru\", \"de\"], label=\"Source Language\", value=\"en\"\n",
        "                )\n",
        "                target_lang = gr.Dropdown(\n",
        "                    [\"en\", \"ru\", \"de\"], label=\"Target Language\", value=\"ru\"\n",
        "                )\n",
        "                duration = gr.Slider(1, 10, value=5, step=1, label=\"Recording Duration (seconds)\")\n",
        "\n",
        "                with gr.Row():\n",
        "                    record_btn = gr.Button(\"üé§ Record & Translate\", variant=\"primary\")\n",
        "                    stop_btn = gr.Button(\"‚èπ Stop\")\n",
        "\n",
        "            with gr.Column():\n",
        "                source_text = gr.Textbox(label=\"Original Text\")\n",
        "                translated_text = gr.Textbox(label=\"Translation\")\n",
        "                audio_output = gr.Audio(label=\"Translated Speech\", type=\"numpy\")\n",
        "\n",
        "        record_btn.click(\n",
        "            fn=translator.process_audio,\n",
        "            inputs=[source_lang, target_lang, duration],\n",
        "            outputs=[source_text, translated_text, audio_output]\n",
        "        )\n",
        "        stop_btn.click(\n",
        "            fn=translator.stop_recording,\n",
        "            outputs=source_text\n",
        "        )\n",
        "\n",
        "    return demo\n",
        "\n",
        "# Launch the interface\n",
        "print(\"üöÄ Starting application...\")\n",
        "demo = create_interface()\n",
        "demo.launch(share=True)"
      ],
      "metadata": {
        "id": "yzPDnCthvAKy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}