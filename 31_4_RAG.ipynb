{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPc8V6/t74ndumaWBc4bn+H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Maxxx-VS/The-Founder/blob/master/31_4_RAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "На 3 балла. Возьми любую книжку в PDF, построй простую RAG-систему, задай вопросы. Примени несколько постобработок, как мы это делали во второй части урока. Проанализируй данные, которые подаются на промпт LLM модели с помощью трассировки и какие ответы выдает RAG система. Сделай выводы (письменно в колабе).\n",
        "\n",
        "На 4 балла. Необходимо выполнить первое задание, продемонстрировав умение пользоваться пакетами LlamaPacks, для этого используй вместо постобработки любой расширенный поисковик из LlamaHub. С помощью трассировки проанализируйте данные на входе в LLM модель. Сделайте выводы (письменно в колабе).\n",
        "\n",
        "На 5 баллов. Вам необходимо настроить NeMo Guardrails или Llama Guard для своей RAG системы. Продемонстрируйте несколько примеров запросов, на которые сработали ограничения \"защитника\"."
      ],
      "metadata": {
        "id": "wVU2tavTjVrB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wkXFxZmSJkZT"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install openai llama-index-core \"arize-phoenix[evals,llama-index]\" gcsfs nest-asyncio \"openinference-instrumentation-llama-index>=2.0.0\"\n",
        "!pip install llama_index --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass # для работы с паролями\n",
        "import os      # для работы с окружением и файловой системой\n",
        "\n",
        "# Запрос ввода ключа от OpenAI\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Введите OpenAI API Key:\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XriLa4i5J1To",
        "outputId": "d77c4c75-ba68-492a-d81c-1da1a64ab163"
      },
      "execution_count": 2,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Введите OpenAI API Key:··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !wget https://storage.yandexcloud.net/academy.ai/LLM/PDF_liquid.zip"
      ],
      "metadata": {
        "id": "yFFGh0aULXH7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !unzip -qo \"AlexanderDumas-TheCountofMonteCristo.zip\" -d ./reports"
      ],
      "metadata": {
        "id": "Mbs1Rx6XNIjJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa9ab676-7ed5-4d5e-cb77-460540726289"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[60654890a4.7z]\n",
            "  End-of-central-directory signature not found.  Either this file is not\n",
            "  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n",
            "  latter case the central directory and zipfile comment will be found on\n",
            "  the last disk(s) of this archive.\n",
            "unzip:  cannot find zipfile directory in one of 60654890a4.7z or\n",
            "        60654890a4.7z.zip, and cannot find 60654890a4.7z.ZIP, period.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -qo \"Austin Pride and Prejudice.zip\" -d ./reports"
      ],
      "metadata": {
        "id": "kh32vnw_e1X3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "from llama_index.llms.openai import OpenAI\n",
        "from llama_index.embeddings.openai import OpenAIEmbedding\n",
        "\n",
        "from llama_index.core import (\n",
        "    VectorStoreIndex,\n",
        "    GPTVectorStoreIndex,\n",
        "    SimpleDirectoryReader,\n",
        "    KeywordTableIndex,\n",
        "    StorageContext,\n",
        "    load_index_from_storage,\n",
        "    ServiceContext,\n",
        "    Settings,)"
      ],
      "metadata": {
        "id": "7nRpPW3nJ8US"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Загружаем файлы PDF\n",
        "documents = SimpleDirectoryReader('./reports').load_data()\n",
        "\n",
        "# Установим модель по умолчанию\n",
        "Settings.llm = OpenAI(temperature=0, model='gpt-3.5-turbo')"
      ],
      "metadata": {
        "collapsed": true,
        "id": "KrVC-WKFLkfw"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index = GPTVectorStoreIndex.from_documents(documents)\n",
        "\n",
        "# Подготавливаем движок к индексу и задем ему вопрос\n",
        "query_engine = index.as_query_engine()"
      ],
      "metadata": {
        "id": "wCkuo6wcKJvI"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\"Write me a short summary of this book. Who is the main antagonist?\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "eiSbGolOKQn7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3de0fe53-ebe0-40e9-b404-a660b2230f82"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The book revolves around the social interactions and relationships of the characters, particularly focusing on the protagonist, Elizabeth, and her encounters with Mr. Darcy and Mr. Wickham. The main antagonist in the story is Mr. Darcy, who is portrayed as having a proud and unforgiving nature, causing conflicts and misunderstandings with the other characters, especially Elizabeth and Mr. Wickham.\n"
          ]
        }
      ]
    }
  ]
}