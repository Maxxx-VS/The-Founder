{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN4Kcmtx3Uq1KZDvq46L01f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Maxxx-VS/The-Founder/blob/master/TG_Bot_%2B_GPT3_5_Turbo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTQL0yTdghPs",
        "outputId": "84b67a23-1605-4f26-b65e-69ec1c5566c7",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: aiogram in /usr/local/lib/python3.10/dist-packages (3.13.1)\n",
            "Requirement already satisfied: aiofiles<24.2,>=23.2.1 in /usr/local/lib/python3.10/dist-packages (from aiogram) (24.1.0)\n",
            "Requirement already satisfied: aiohttp<3.11,>=3.9.0 in /usr/local/lib/python3.10/dist-packages (from aiogram) (3.10.5)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from aiogram) (2024.8.30)\n",
            "Requirement already satisfied: magic-filter<1.1,>=1.0.12 in /usr/local/lib/python3.10/dist-packages (from aiogram) (1.0.12)\n",
            "Requirement already satisfied: pydantic<2.10,>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from aiogram) (2.9.2)\n",
            "Requirement already satisfied: typing-extensions<=5.0,>=4.7.0 in /usr/local/lib/python3.10/dist-packages (from aiogram) (4.12.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<3.11,>=3.9.0->aiogram) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<3.11,>=3.9.0->aiogram) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<3.11,>=3.9.0->aiogram) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<3.11,>=3.9.0->aiogram) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<3.11,>=3.9.0->aiogram) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<3.11,>=3.9.0->aiogram) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<3.11,>=3.9.0->aiogram) (4.0.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2.10,>=2.4.1->aiogram) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<2.10,>=2.4.1->aiogram) (2.23.4)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.0->aiohttp<3.11,>=3.9.0->aiogram) (3.10)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.10/dist-packages (1.6.0)\n",
            "Requirement already satisfied: mwclient in /usr/local/lib/python3.10/dist-packages (0.11.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from mwclient) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib->mwclient) (3.2.2)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib->mwclient) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0.0->requests-oauthlib->mwclient) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0.0->requests-oauthlib->mwclient) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0.0->requests-oauthlib->mwclient) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0.0->requests-oauthlib->mwclient) (2024.8.30)\n",
            "Requirement already satisfied: mwparserfromhell in /usr/local/lib/python3.10/dist-packages (0.6.6)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.46.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.5.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.7.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.9.11)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.8.30)\n"
          ]
        }
      ],
      "source": [
        "# Устанавливаем необходимые библиотеки\n",
        "!pip install aiogram\n",
        "!pip install nest_asyncio\n",
        "!pip install mwclient\n",
        "!pip install mwparserfromhell\n",
        "!pip install openai\n",
        "!pip install tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Импортируем необходимые библиотеки\n",
        "import asyncio\n",
        "import logging\n",
        "from aiogram import Bot, Dispatcher, types\n",
        "from aiogram.filters.command import Command\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "import time\n",
        "import mwclient\n",
        "import mwparserfromhell\n",
        "import openai\n",
        "import pandas as pd\n",
        "import re\n",
        "import tiktoken\n",
        "from openai import OpenAI\n",
        "import os\n",
        "import getpass\n",
        "from scipy import spatial"
      ],
      "metadata": {
        "collapsed": true,
        "id": "4d48Ijklhy-z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3aaec2a4-c79f-4b32-c5c2-660daafe12ed"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Подготовка данных из Википедии про MIT\n",
        "CATEGORY_TITLE = \"Category:Massachusetts Institute of Technology\"\n",
        "WIKI_SITE = \"en.wikipedia.org\"\n",
        "\n",
        "# Соберем заголовки всех статей\n",
        "def titles_from_category(\n",
        "    category: mwclient.listing.Category, # Задаем типизированный параметр категории статей\n",
        "    max_depth: int # Определяем глубину вложения статей\n",
        ") -> set[str]:\n",
        "    \"\"\"Возвращает набор заголовков страниц в данной категории Википедии и ее подкатегориях.\"\"\"\n",
        "    titles = set() # Используем множество для хранения заголовков статей\n",
        "    for cm in category.members(): # Перебираем вложенные объекты категории\n",
        "        if type(cm) == mwclient.page.Page: # Если объект является страницей\n",
        "            titles.add(cm.name) # в хранилище заголовков добавляем имя страницы\n",
        "        elif isinstance(cm, mwclient.listing.Category) and max_depth > 0: # Если объект является категорией и глубина вложения не достигла максимальной\n",
        "            deeper_titles = titles_from_category(cm, max_depth=max_depth - 1) # вызываем рекурсивно функцию для подкатегории\n",
        "            titles.update(deeper_titles) # добавление в множество элементов из другого множества\n",
        "    return titles\n",
        "\n",
        "# Инициализация объекта MediaWiki\n",
        "# WIKI_SITE ссылается на англоязычную часть Википедии\n",
        "site = mwclient.Site(WIKI_SITE)\n",
        "\n",
        "# Загрузка раздела заданной категории\n",
        "category_page = site.pages[CATEGORY_TITLE]\n",
        "# Получение множества всех заголовков категории с вложенностью на один уровень\n",
        "titles = titles_from_category(category_page, max_depth=1)\n",
        "\n",
        "print(f\"Создано {len(titles)} заголовков статей в категории {CATEGORY_TITLE}.\")"
      ],
      "metadata": {
        "id": "DD2TjEYgsA9A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ed84edb-03ce-4b81-9711-ce0b44f7deca"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Создано 355 заголовков статей в категории Category:Massachusetts Institute of Technology.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Задаем секции, которые будут отброшены при парсинге статей\n",
        "SECTIONS_TO_IGNORE = [\n",
        "    'Robert Meservey', 'T. Colin Campbell',\n",
        "    'Massachusetts Institute of Technology School of Engineering',\n",
        "    'Sparcle', 'Deborah Leckband', 'RoboTuna', 'Busting Vegas',\n",
        "]"
      ],
      "metadata": {
        "id": "tu2maUSry4l-"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Функция возвращает список всех вложенных секций для заданной секции страницы Википедии\n",
        "def all_subsections_from_section(\n",
        "    section: mwparserfromhell.wikicode.Wikicode, # текущая секция\n",
        "    parent_titles: list[str], # Заголовки родителя\n",
        "    sections_to_ignore: set[str], # Секции, которые необходимо проигнорировать\n",
        ") -> list[tuple[list[str], str]]:\n",
        "    \"\"\"\n",
        "    Из раздела Википедии возвращает список всех вложенных секций.\n",
        "    Каждый подраздел представляет собой кортеж, где:\n",
        "      - первый элемент представляет собой список родительских секций, начиная с заголовка страницы\n",
        "      - второй элемент представляет собой текст секции\n",
        "    \"\"\"\n",
        "\n",
        "    # Извлекаем заголовки текущей секции\n",
        "    headings = [str(h) for h in section.filter_headings()]\n",
        "    title = headings[0]\n",
        "    # Заголовки Википедии имеют вид: \"== Heading ==\"\n",
        "\n",
        "    if title.strip(\"=\" + \" \") in sections_to_ignore:\n",
        "        # Если заголовок секции в списке для игнора, то пропускаем его\n",
        "        return []\n",
        "\n",
        "    # Объединим заголовки и подзаголовки, чтобы сохранить контекст для chatGPT\n",
        "    titles = parent_titles + [title]\n",
        "\n",
        "    # Преобразуем wikicode секции в строку\n",
        "    full_text = str(section)\n",
        "\n",
        "    # Выделяем текст секции без заголовка\n",
        "    section_text = full_text.split(title)[1]\n",
        "    if len(headings) == 1:\n",
        "        # Если один заголовок, то формируем результирующий список\n",
        "        return [(titles, section_text)]\n",
        "    else:\n",
        "        first_subtitle = headings[1]\n",
        "        section_text = section_text.split(first_subtitle)[0]\n",
        "        # Формируем результирующий список из текста до первого подзаголовка\n",
        "        results = [(titles, section_text)]\n",
        "        for subsection in section.get_sections(levels=[len(titles) + 1]):\n",
        "            results.extend(\n",
        "                # Вызываем функцию получения вложенных секций для заданной секции\n",
        "                all_subsections_from_section(subsection, titles, sections_to_ignore)\n",
        "                )  # Объединяем результирующие списки данной функции и вызываемой\n",
        "        return results\n",
        "\n",
        "# Функция возвращает список всех секций страницы, за исключением тех, которые отбрасываем\n",
        "def all_subsections_from_title(\n",
        "    title: str, # Заголовок статьи Википедии, которую парсим\n",
        "    sections_to_ignore: set[str] = SECTIONS_TO_IGNORE, # Секции, которые игнорируем\n",
        "    site_name: str = WIKI_SITE, # Ссылка на сайт википедии\n",
        ") -> list[tuple[list[str], str]]:\n",
        "    \"\"\"\n",
        "    Из заголовка страницы Википедии возвращает список всех вложенных секций.\n",
        "    Каждый подраздел представляет собой кортеж, где:\n",
        "      - первый элемент представляет собой список родительских секций, начиная с заголовка страницы\n",
        "      - второй элемент представляет собой текст секции\n",
        "    \"\"\"\n",
        "\n",
        "    # Инициализация объекта MediaWiki\n",
        "    # WIKI_SITE ссылается на англоязычную часть Википедии\n",
        "    site = mwclient.Site(site_name)\n",
        "\n",
        "    # Запрашиваем страницу по заголовку\n",
        "    page = site.pages[title]\n",
        "\n",
        "    # Получаем текстовое представление страницы\n",
        "    text = page.text()\n",
        "\n",
        "    # Удобный парсер для MediaWiki\n",
        "    parsed_text = mwparserfromhell.parse(text)\n",
        "    # Извлекаем заголовки\n",
        "    headings = [str(h) for h in parsed_text.filter_headings()]\n",
        "    if headings: # Если заголовки найдены\n",
        "        # В качестве резюме берем текст до первого заголовка\n",
        "        summary_text = str(parsed_text).split(headings[0])[0]\n",
        "    else:\n",
        "        # Если нет заголовков, то весь текст считаем резюме\n",
        "        summary_text = str(parsed_text)\n",
        "    results = [([title], summary_text)] # Добавляем резюме в результирующий список\n",
        "    for subsection in parsed_text.get_sections(levels=[2]): # Извлекаем секции 2-го уровня\n",
        "        results.extend(\n",
        "            # Вызываем функцию получения вложенных секций для заданной секции\n",
        "            all_subsections_from_section(subsection, [title], sections_to_ignore)\n",
        "        ) # Объединяем результирующие списки данной функции и вызываемой\n",
        "    return results"
      ],
      "metadata": {
        "id": "8r_zv5lL0LwT"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Разбивка статей на секции\n",
        "wikipedia_sections = []\n",
        "for title in titles:\n",
        "    wikipedia_sections.extend(all_subsections_from_title(title))\n",
        "print(f\"Найдено {len(wikipedia_sections)} секций на {len(titles)} страницах\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lG0K55Jc0uBN",
        "outputId": "f58770c4-0c0d-40e1-d4de-a3b19c90383e"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Найдено 3010 секций на 355 страницах\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Очистка текста секции от ссылок <ref>xyz</ref>, начальных и конечных пробелов\n",
        "def clean_section(section: tuple[list[str], str]) -> tuple[list[str], str]:\n",
        "    titles, text = section\n",
        "    # Удаляем ссылки\n",
        "    text = re.sub(r\"<ref.*?</ref>\", \"\", text)\n",
        "    # Удаляем пробелы вначале и конце\n",
        "    text = text.strip()\n",
        "    return (titles, text)\n",
        "\n",
        "# Применим функцию очистки ко всем секциям с помощью генератора списков\n",
        "wikipedia_sections = [clean_section(ws) for ws in wikipedia_sections]\n",
        "\n",
        "# Отфильтруем короткие и пустые секции\n",
        "def keep_section(section: tuple[list[str], str]) -> bool:\n",
        "    \"\"\"Возвращает значение True, если раздел должен быть сохранен, в противном случае значение False.\"\"\"\n",
        "    titles, text = section\n",
        "    # Фильтруем по произвольной длине, можно выбрать и другое значение\n",
        "    if len(text) < 16:\n",
        "        return False\n",
        "    else:\n",
        "        return True\n",
        "\n",
        "original_num_sections = len(wikipedia_sections)\n",
        "wikipedia_sections = [ws for ws in wikipedia_sections if keep_section(ws)]\n",
        "print(f\"Отфильтровано {original_num_sections-len(wikipedia_sections)} секций, осталось {len(wikipedia_sections)} секций.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJSA3LV72e5E",
        "outputId": "a340fe8d-c086-43bb-ab63-e8de0e926134"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Отфильтровано 268 секций, осталось 2742 секций.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# выведем 3 секции\n",
        "for ws in wikipedia_sections[:3]:\n",
        "    print(ws[0])\n",
        "    display(ws[1][:50] + \"...\")\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "id": "YrOkNbED2l7X",
        "outputId": "3185488b-1aa1-486b-a4a5-033629eb018b"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Stata Center']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'{{Short description|Academic building in Cambridge...'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "['Stata Center', '==Description==']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'[[File:View out the window of the Stata Center (20...'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "['Stata Center', '==History==']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'{{Main|Building 20}}\\nThe Stata Center is located o...'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "GPT_MODEL = \"gpt-3.5-turbo\"  # only matters insofar as it selects which tokenizer to use\n",
        "\n",
        "# Функция подсчета токенов\n",
        "def num_tokens(text: str, model: str = GPT_MODEL) -> int:\n",
        "    \"\"\"Возвращает число токенов в строке.\"\"\"\n",
        "    encoding = tiktoken.encoding_for_model(model)\n",
        "    return len(encoding.encode(text))\n",
        "\n",
        "# Функция разделения строк\n",
        "def halved_by_delimiter(string: str, delimiter: str = \"\\n\") -> list[str, str]:\n",
        "    \"\"\"Разделяет строку надвое с помощью разделителя (delimiter), пытаясь сбалансировать токены с каждой стороны.\"\"\"\n",
        "\n",
        "    # Делим строку на части по разделителю, по умолчанию \\n - перенос строки\n",
        "    chunks = string.split(delimiter)\n",
        "    if len(chunks) == 1:\n",
        "        return [string, \"\"]  # разделитель не найден\n",
        "    elif len(chunks) == 2:\n",
        "        return chunks  # нет необходимости искать промежуточную точку\n",
        "    else:\n",
        "        # Считаем токены\n",
        "        total_tokens = num_tokens(string)\n",
        "        halfway = total_tokens // 2\n",
        "        # Предварительное разделение по середине числа токенов\n",
        "        best_diff = halfway\n",
        "        # В цикле ищем какой из разделителей, будет ближе всего к best_diff\n",
        "        for i, chunk in enumerate(chunks):\n",
        "            left = delimiter.join(chunks[: i + 1])\n",
        "            left_tokens = num_tokens(left)\n",
        "            diff = abs(halfway - left_tokens)\n",
        "            if diff >= best_diff:\n",
        "                break\n",
        "            else:\n",
        "                best_diff = diff\n",
        "        left = delimiter.join(chunks[:i])\n",
        "        right = delimiter.join(chunks[i:])\n",
        "        # Возвращаем левую и правую часть оптимально разделенной строки\n",
        "        return [left, right]\n",
        "\n",
        "# Функция обрезает строку до максимально разрешенного числа токенов\n",
        "def truncated_string(\n",
        "    string: str, # строка\n",
        "    model: str, # модель\n",
        "    max_tokens: int, # максимальное число разрешенных токенов\n",
        "    print_warning: bool = True, # флаг вывода предупреждения\n",
        ") -> str:\n",
        "    \"\"\"Обрезка строки до максимально разрешенного числа токенов.\"\"\"\n",
        "    encoding = tiktoken.encoding_for_model(model)\n",
        "    encoded_string = encoding.encode(string)\n",
        "    # Обрезаем строку и декодируем обратно\n",
        "    truncated_string = encoding.decode(encoded_string[:max_tokens])\n",
        "    if print_warning and len(encoded_string) > max_tokens:\n",
        "        print(f\"Предупреждение: Строка обрезана с {len(encoded_string)} токенов до {max_tokens} токенов.\")\n",
        "    # Усеченная строка\n",
        "    return truncated_string\n",
        "\n",
        "# Функция делит секции статьи на части по максимальному числу токенов\n",
        "def split_strings_from_subsection(\n",
        "    subsection: tuple[list[str], str], # секции\n",
        "    max_tokens: int = 1000, # максимальное число токенов\n",
        "    model: str = GPT_MODEL, # модель\n",
        "    max_recursion: int = 5, # максимальное число рекурсий\n",
        ") -> list[str]:\n",
        "    \"\"\"\n",
        "    Разделяет секции на список из частей секций, в каждой части не более max_tokens.\n",
        "    Каждая часть представляет собой кортеж родительских заголовков [H1, H2, ...] и текста (str).\n",
        "    \"\"\"\n",
        "    titles, text = subsection\n",
        "    string = \"\\n\\n\".join(titles + [text])\n",
        "    num_tokens_in_string = num_tokens(string)\n",
        "    # Если длина соответствует допустимой, то вернет строку\n",
        "    if num_tokens_in_string <= max_tokens:\n",
        "        return [string]\n",
        "    # если в результате рекурсия не удалось разделить строку, то просто усечем ее по числу токенов\n",
        "    elif max_recursion == 0:\n",
        "        return [truncated_string(string, model=model, max_tokens=max_tokens)]\n",
        "    # иначе разделим пополам и выполним рекурсию\n",
        "    else:\n",
        "        titles, text = subsection\n",
        "        for delimiter in [\"\\n\\n\", \"\\n\", \". \"]: # Пробуем использовать разделители от большего к меньшему (разрыв, абзац, точка)\n",
        "            left, right = halved_by_delimiter(text, delimiter=delimiter)\n",
        "            if left == \"\" or right == \"\":\n",
        "                # если какая-либо половина пуста, повторяем попытку с более простым разделителем\n",
        "                continue\n",
        "            else:\n",
        "                # применим рекурсию на каждой половине\n",
        "                results = []\n",
        "                for half in [left, right]:\n",
        "                    half_subsection = (titles, half)\n",
        "                    half_strings = split_strings_from_subsection(\n",
        "                        half_subsection,\n",
        "                        max_tokens=max_tokens,\n",
        "                        model=model,\n",
        "                        max_recursion=max_recursion - 1, # уменьшаем максимальное число рекурсий\n",
        "                    )\n",
        "                    results.extend(half_strings)\n",
        "                return results\n",
        "    # иначе никакого разделения найдено не было, поэтому просто обрезаем строку (должно быть очень редко)\n",
        "    return [truncated_string(string, model=model, max_tokens=max_tokens)]"
      ],
      "metadata": {
        "id": "pRKnmH8125vy"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Делим секции на части\n",
        "MAX_TOKENS = 1600\n",
        "wikipedia_strings = []\n",
        "for section in wikipedia_sections:\n",
        "    wikipedia_strings.extend(split_strings_from_subsection(section, max_tokens=MAX_TOKENS))\n",
        "\n",
        "print(f\"{len(wikipedia_sections)} секций Википедии поделены на {len(wikipedia_strings)} строк.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2AXDE9fEeJn",
        "outputId": "cc9fe151-a988-4578-982f-758f82dda06d"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2742 секций Википедии поделены на 2773 строк.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Напечатаем пример строки\n",
        "print(wikipedia_strings[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NiLIbTH2EljI",
        "outputId": "c880b6eb-f753-420d-a8e7-501e02b7c131"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stata Center\n",
            "\n",
            "==Description==\n",
            "\n",
            "[[File:View out the window of the Stata Center (20 July 2004).jpg|thumb|upright=1.1|View from an upper-floor window]]\n",
            "[[File:MIT Stata Center self-reflection.jpg|thumb|upright=1.1|Stata Center self reflection]]\n",
            "In contrast to the MIT custom of referring to buildings by their numbers rather than their official names, the complex is usually referred to as \"Stata\" or \"the Stata Center\" (though the building number is still essential in identifying rooms at MIT). Above the fourth floor, the building splits into two distinct structures: the Gates Tower and the Dreyfoos Tower, often called \"G Tower\" and \"D Tower\" respectively.\n",
            "\n",
            "The building has a number of small auditoriums and classrooms used by the Electrical Engineering and Computer Science department (EECS, Course 6), as well as other departments and on-campus groups.  Research labs and offices of the [[MIT Computer Science and Artificial Intelligence Laboratory|Computer Science and Artificial Intelligence Laboratory]] (CSAIL), the [[MIT Laboratory for Information and Decision Systems|Laboratory for Information and Decision Systems]] (LIDS), as well as the Department of [[Linguistics]] and [[Philosophy]] (Course 24) occupy the upper floors. Academic celebrities such as [[Noam Chomsky]], [[Ron Rivest]], and [[World Wide Web Consortium]] founder [[Tim Berners-Lee]] also have offices in the building.\n",
            "\n",
            "A wide main passage running the length of the building on the ground floor is called the [[Charles M. Vest]] Student Street, in honor of the former MIT president who died in December 2013. The Student Street is often used as a more-spacious substitute or extension for the Memorial Lobby located in Building 10 on the [[Infinite Corridor]].  The monthly \"Choose to Re-use\" community recycling swap fest, and a weekly fresh produce market are other events regularly held in the Stata Center. One of five MIT Technology Childcare Centers (TCC) is located at the western end of the ground floor.  The Forbes Family Cafe is located at the eastern end, and serves coffee and lunch to the public during office hours.\n",
            "\n",
            "The [[MIT Museum]] maintains some historic displays on the ground floor of the Stata Center. A few selected larger relics of past [[MIT hacks|hacks]] (student pranks) are now on semi-permanent display, including a \"fire hose\" drinking fountain, a giant [[slide rule]], and full-size replicas of a cow and a police car that had been placed atop the Great Dome (though not at the same time). In the ground floor elevator lobby of the Dreyfoos Tower are located a large [[time capsule]] box plus informational panels describing MIT's historic [[Building 20]], which the Stata Center has replaced.\n",
            "\n",
            "A large [[Digi-Comp II]] mechanical digital computer which operates with [[billiard ball]]s is located in the ground floor elevator lobby of the Gates Tower. Also located there is ''Flow'', a large multicolor art display created by Karl Sims (an MIT alumnus and [[MacArthur Fellow|MacArthur \"genius\"]]), which is activated by visitors' movements as detected by a [[Microsoft Kinect]] sensor.\n",
            "\n",
            "Major funding for the Stata Center was provided by [[Ray Stata]] (MIT class of 1957) and Maria Stata. [[Bill Gates]] donated US$20 million, causing MIT to name one tower the \"Gates Building.\"Other major funders included [[Alexander W. Dreyfoos Jr.]] (MIT class of 1954), Charles Thomas \"E.B.\" Pritchard Hintze (an MIT graduate, and of [[JD Edwards]], now [[Oracle Corporation]]), [[Morris Chang]] of [[TSMC]]. and [[Michael Dertouzos]].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EMBEDDING_MODEL = \"text-embedding-ada-002\"  # Модель токенизации от OpenAI\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Введите OpenAI API Key:\")\n",
        "client = OpenAI(api_key = os.environ.get(\"OPENAI_API_KEY\"))\n",
        "# Функция отправки chatGPT строки для ее токенизации (вычисления эмбедингов)\n",
        "def get_embedding(text, model=\"text-embedding-ada-002\"):\n",
        "   return client.embeddings.create(input = [text], model=model).data[0].embedding"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxLwEwiuE-D2",
        "outputId": "2e003728-1a98-4666-a638-a2044123b83e"
      },
      "execution_count": 48,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Введите OpenAI API Key:··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame({\"text\": wikipedia_strings[:10]})\n",
        "df['embedding'] = df.text.apply(lambda x: get_embedding(x, model='text-embedding-ada-002'))\n",
        "SAVE_PATH = \"./MIT.csv\"\n",
        "# Сохранение результата\n",
        "df.to_csv(SAVE_PATH, index=False)\n",
        "df.tail(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "jBXYXaeqj_Aq",
        "outputId": "47aaac3f-ed27-4319-9df6-b787f6a1cab9"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  \\\n",
              "7  Stata Center\\n\\n== See also ==\\n\\n* [[List of ...   \n",
              "8  Stata Center\\n\\n== References ==\\n\\n'''Notes''...   \n",
              "9  Stata Center\\n\\n== External links ==\\n\\n{{Comm...   \n",
              "\n",
              "                                           embedding  \n",
              "7  [-0.012352237477898598, 0.01973605528473854, 0...  \n",
              "8  [-0.012329358607530594, 0.0037225831765681505,...  \n",
              "9  [-0.020836565643548965, 0.009624185971915722, ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-355438db-c0cf-4f4f-acd3-9d340cc0430f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>embedding</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Stata Center\\n\\n== See also ==\\n\\n* [[List of ...</td>\n",
              "      <td>[-0.012352237477898598, 0.01973605528473854, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Stata Center\\n\\n== References ==\\n\\n'''Notes''...</td>\n",
              "      <td>[-0.012329358607530594, 0.0037225831765681505,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Stata Center\\n\\n== External links ==\\n\\n{{Comm...</td>\n",
              "      <td>[-0.020836565643548965, 0.009624185971915722, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-355438db-c0cf-4f4f-acd3-9d340cc0430f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-355438db-c0cf-4f4f-acd3-9d340cc0430f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-355438db-c0cf-4f4f-acd3-9d340cc0430f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9c6f9263-7409-4462-8ee8-928083c2e152\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9c6f9263-7409-4462-8ee8-928083c2e152')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9c6f9263-7409-4462-8ee8-928083c2e152 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Stata Center\\n\\n== See also ==\\n\\n* [[List of works by Frank Gehry]]\\n* [[Marqu\\u00e9s de Riscal Hotel]], Spain\",\n          \"Stata Center\\n\\n== References ==\\n\\n'''Notes'''\\n{{Reflist|30em}}\\n\\n'''Bibliography'''\\n* {{cite book |first=Nancy E.|last=Joyce|others=afterword by William J. Mitchell, photography by Richard Sobol |title=Building Stata: The Design and Construction of Frank O. Gehry's Stata Center at MIT|publisher=[[The MIT Press]] |location=Cambridge, Massachusetts|year=2004\\n|isbn=978-0-262-60061-3}}\\n* {{cite book | first=William J.| last=Mitchell| title=Imagining MIT: Designing a Campus for the Twenty-First Century | year=2007 | publisher=[[The MIT Press]]|location=Cambridge, Massachusetts | isbn=978-0-262-13479-8}}\",\n          \"Stata Center\\n\\n== External links ==\\n\\n{{Commons category|Stata Center (MIT Building 32)}}\\n* {{cite web|title=Stata Center|url=http://web.mit.edu/facilities/construction/completed/stata.html|publisher=MIT Department of Facilities, Massachusetts Institute of Technology|access-date=2007-09-23}}\\n* {{cite web|title=A multimedia walking tour of the Stata Center|url=http://www.untravelmedia.com/tours/1/untravel_mit_stata_center/|publisher=Untravel Media, Massachusetts Institute of Technology startup|access-date=2008-06-19}}\\n* {{cite web|title=Ray and Maria Stata Center|url=http://www.csail.mit.edu/events/news/stata.html|publisher=MIT Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology|access-date=2007-09-23 |archive-url = https://web.archive.org/web/20070918230328/http://www.csail.mit.edu/events/news/stata.html <!-- Bot retrieved archive --> |archive-date = 2007-09-18}}\\n* {{cite journal|author=Reiss, Spencer|title=Frank Gehry's Geek Palace|url=https://www.wired.com/wired/archive/12.05/mit.html|journal=Wired, Cond\\u00e9Net Inc.|date=May 2004|issue=12.05|access-date=2007-09-23|doi=10.1007/s11916-004-0076-y|volume=8|pages=518\\u2013522|pmid=15509468|s2cid=22507905}}\\n* {{cite news|author=Beam, Alex|title=After buildup, MIT center is a letdown|url=http://www.boston.com/news/globe/living/articles/2004/05/04/after_buildup_mit_center_is_a_letdown/|work=The Boston Globe|publisher=The New York Times Company|date=2004-05-04|access-date=2007-09-23}}\\n* {{cite news|author=Ted Smalley Bowen|title=MIT's Stata Center Opens, Raises Questions about Cost Control|url=http://www.construction.com/NewsCenter/Headlines/AR/20040519r.asp|work=Architectural Record|publisher=The McGraw-Hill Companies, Inc. (construction.com)|date=2004-05-19|access-date=2007-09-23 |archive-url = https://web.archive.org/web/20070929091636/http://www.construction.com/NewsCenter/Headlines/AR/20040519r.asp <!-- Bot retrieved archive --> |archive-date = 2007-09-29}}\\n* {{cite web|author=Wollman, Garrett A.|title=Building MIT's Stata Center: An IT Perspective|url=http://www.usenix.org/event/lisa05/tech/wollman/index.html|format=KPresenter|work=Lisa'05 Conference Proceedings|publisher=USENIX (usenix.org)|date=2005-12-20|access-date=2016-11-28}}\\n* Virtual tour: {{cite web\\n |author     = MIT Computer Science and Artificial Intelligence Laboratory\\n |title      = CSAIL Lab Virtual Tours - Information Desk\\n |date       = n.d.\\n |url        = http://www.csail.mit.edu/tours/virtual/02_Infodesk.html\\n |archive-url = https://web.archive.org/web/20060427120216/http://www.csail.mit.edu/tours/virtual/02_Infodesk.html\\n |url-status   = dead\\n |archive-date = 2006-04-27\\n |access-date = 2006-12-26\\n}}\\n* {{Structurae | id = 20010295 | title = Ray and Maria Stata Center }}\\n\\n'''Maps'''\\n* {{cite web|title=Campus Map: Building 32 (Ray and Maria Stata Center)|url=http://whereis.mit.edu/map-jpg?selection=32;selectfield=facility;selectlayer=Buildings|publisher=MIT Department of Facilities and Information Services & Technology, Massachusetts Institute of Technology|access-date=2007-09-23}}\\n\\n{{Coord|42.361640|-71.090255|type:landmark_region:US|display=title}}\\n\\n{{MIT}}\\n{{Frank Gehry}}\\n{{Authority control}}\\n\\n[[Category:Buildings and structures completed in 2004]]\\n[[Category:Deconstructivism]]\\n[[Category:Frank Gehry buildings]]\\n[[Category:Massachusetts Institute of Technology buildings]]\\n[[Category:Modernist architecture in Massachusetts]]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"embedding\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Функция поиска\n",
        "def strings_ranked_by_relatedness(\n",
        "    query: str, # пользовательский запрос\n",
        "    df: pd.DataFrame, # DataFrame со столбцами text и embedding (база знаний)\n",
        "    relatedness_fn=lambda x, y: 1 - spatial.distance.cosine(x, y), # функция схожести, косинусное расстояние\n",
        "    top_n: int = 100 # выбор лучших n-результатов\n",
        ") -> tuple[list[str], list[float]]: # Функция возвращает кортеж двух списков, первый содержит строки, второй - числа с плавающей запятой\n",
        "    \"\"\"Возвращает строки и схожести, отсортированные от большего к меньшему\"\"\"\n",
        "\n",
        "    # Отправляем в OpenAI API пользовательский запрос для токенизации\n",
        "    query_embedding_response = openai.embeddings.create(\n",
        "        model=EMBEDDING_MODEL,\n",
        "        input=query,)\n",
        "\n",
        "    # Получен токенизированный пользовательский запрос\n",
        "    query_embedding = query_embedding_response.data[0].embedding\n",
        "\n",
        "    # Сравниваем пользовательский запрос с каждой токенизированной строкой DataFrame\n",
        "    strings_and_relatednesses = [\n",
        "        (row[\"text\"], relatedness_fn(query_embedding, row[\"embedding\"]))\n",
        "        for i, row in df.iterrows()]\n",
        "\n",
        "    # Сортируем по убыванию схожести полученный список\n",
        "    strings_and_relatednesses.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Преобразовываем наш список в кортеж из списков\n",
        "    strings, relatednesses = zip(*strings_and_relatednesses)\n",
        "\n",
        "    # Возвращаем n лучших результатов\n",
        "    return strings[:top_n], relatednesses[:top_n]"
      ],
      "metadata": {
        "id": "2HgzxXLKk5LE"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "strings, relatednesses = strings_ranked_by_relatedness(\"curling gold medal\", df, top_n=5)\n",
        "for string, relatedness in zip(strings, relatednesses):\n",
        "    print(f\"{relatedness=:.3f}\")\n",
        "    display(string)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 777
        },
        "id": "iN8DjlILlG7o",
        "outputId": "a9f439d2-39a6-408d-eba7-31a31d0a864b",
        "collapsed": true
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "relatedness=0.721\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'Stata Center\\n\\n==Lawsuit==\\n\\n[[Image:MIT Stata Center-sprinker explosion-2007.jpg|thumb|upright=1.1|Water spray from a [[fire sprinkler system]] failure in 2007]]\\nOn October 31, 2007,<ref>{{cite news|author=Dey, Arkajit|title=MIT Sues Gehry Firm Over Stata Problems; Lawsuit Describes Persistent Leaks, Sliding Ice and Snow, and Cracking Masonry|work=The Tech|url=http://tech.mit.edu/V127/N53/lawsuit.html|page=1\\n|date=November 9, 2007|access-date=2007-11-09}}</ref><!-- if someone wants to add them, there are some good quotes and info in this The Tech piecwe, that were not in the articles in the Boston Globe or NY Times --> MIT sued<ref>{{cite news|author=Glahn, Lisa F. of Mintz Levin|title=Massachusetts Institute of Technology v. Frank O. Gehry & Associates, Inc., n/k/a Gehry Partners, LLP and Beacon Skanska Construction Company, n/k/a Skanska USA Building, Inc.|work=The Tech|url=http://tech.mit.edu/V127/N53/lawsuit/stata_lawsuit.pdf\\n|date=October 31, 2007|access-date=2007-11-09}}</ref><!-- someone might want to see if the court case is on line at the court and add a {{cite court|...|,,,}} citation--> architect Frank Gehry and the construction companies, [[Skanska]] USA Building Inc. and NER Construction Management, for \"providing deficient design services and drawings\" which caused leaks to spring, masonry to crack, mold to grow, drainage to back up, and falling ice and debris to block emergency exits. A Skanska spokesperson said that, prior to construction, Gehry ignored warnings from Skanska and a consulting company regarding flaws in his design of an outdoor [[amphitheater]], and rejected a formal request from Skanska to modify the design.<ref name=\"globe20071106\" />\\n\\nIn a 2007 interview, Gehry, whose firm had been paid $15 million for the project, said construction problems were inevitable in the design of complex buildings.  \"These things are complicated\", he said, \"and they involved a lot of people, and you never quite know where they went wrong. A building goes together with seven billion pieces of connective tissue. The chances of it getting done ever without something colliding or some misstep are small\". \"I think the issues are fairly minor\", he added. \"M.I.T. is after our insurance.\" Gehry said that [[value engineering]], the process by which elements of a project are eliminated to cut costs, was largely responsible for the problems. \"There are things that were left out of the design\", he said. \"The client chose not to put certain devices on the roofs, to save money.\"\\n\\nThe lawsuit was reportedly settled in 2010 with most of the issues having been resolved.{{clear left}}'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "relatedness=0.719\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'Stata Center\\n\\n== Architectural criticism ==\\n\\nRobert Campbell, architecture columnist for \\'\\'[[The Boston Globe]]\\'\\', wrote a glowing appraisal of the building on April 25, 2004. According to Campbell, \"the Stata is always going to look unfinished. It also looks as if it\\'s about to collapse. Columns tilt at scary angles. Walls teeter, swerve, and collide in random curves and angles. Materials change wherever you look: brick, mirror-surface steel, [[brushed metal|brushed]] aluminum, brightly colored paint, corrugated metal. Everything looks improvised, as if thrown up at the last moment. That\\'s the point. The Stata\\'s appearance is a metaphor for the freedom, daring, and creativity of the research that\\'s supposed to occur inside it.\" Campbell stated that the cost overruns and delays in completion of the Stata Center are of no more importance than similar problems associated with the building of [[St Paul\\'s Cathedral]]. The 2005 [[Kaplan, Inc.|Kaplan]]/\\'\\'[[Newsweek]]\\'\\' guide \\'\\'How to Get into College\\'\\', which lists twenty-five universities its editors consider notable in some respect, recognizes MIT as having the \"hottest architecture\", placing most of its emphasis on the Stata Center.\\n\\nThough there are many who praise this building, and in fact from the perspective of Gehry\\'s other work it is considered by some as one of his best, there are certainly many who are less enamored of the structure. Mathematician and architectural theorist [[Nikos Salingaros]] has harshly criticized the Stata Center:\\n\\n{{Quote | style=font-size:100% |An architecture that reverses structural algorithms so as to create disorder&nbsp;— the same algorithms that in an infinitely more detailed application generate living form—ceases to be architecture. Deconstructivist buildings are the most visible symbols of actual deconstruction. The randomness they embody is the antithesis of nature\\'s organized complexity. This is despite effusive praise in the press for \"exciting\" new academic buildings, such as the Peter B. Lewis Management Building at Case Western Reserve University in Cleveland, the Vontz Center for Molecular Studies at the University of Cincinnati Medical Center, and the Stata Center for Computer, Information, and Intelligence Sciences at MIT, all by Frank Gehry. Housing a scientific department at a university inside the symbol of its nemesis must be the ultimate irony.}}\\n\\nFormer [[Boston University]] president [[John Silber]] said the building \"really is a disaster\". Architecture critic Robert Campbell praised Gehry for \"break[ing] up the monotony of a street of concrete buildings\" and being \"a building like no other building\". The building has also been described as \"reminiscent of a [[Dr. Seuss]] creation\".'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "relatedness=0.713\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\"Stata Center\\n\\n== References ==\\n\\n'''Notes'''\\n{{Reflist|30em}}\\n\\n'''Bibliography'''\\n* {{cite book |first=Nancy E.|last=Joyce|others=afterword by William J. Mitchell, photography by Richard Sobol |title=Building Stata: The Design and Construction of Frank O. Gehry's Stata Center at MIT|publisher=[[The MIT Press]] |location=Cambridge, Massachusetts|year=2004\\n|isbn=978-0-262-60061-3}}\\n* {{cite book | first=William J.| last=Mitchell| title=Imagining MIT: Designing a Campus for the Twenty-First Century | year=2007 | publisher=[[The MIT Press]]|location=Cambridge, Massachusetts | isbn=978-0-262-13479-8}}\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "relatedness=0.712\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'Stata Center\\n\\n==Gallery==\\n\\n<gallery widths=\"200px\" heights=\"200px\" center mode=packed>\\nImage:MIT Strata Center.jpg|Stata Center\\nImage:The Ray and Maria Stata Center galawebdesign.jpg|View from the 7th floor\\nImage:Stata Center-20050310-2.jpg|Interior, ground floor, Gates tower\\nImage:MIT-Building32-from-54-at-night.jpg|Building 32 at night\\nImage:Bldg 20 time capsule.jpg|Building 20 time capsule, on display in the Stata Center\\n</gallery>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "relatedness=0.707\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'Stata Center\\n\\n==History==\\n\\n{{Main|Building 20}}\\nThe Stata Center is located on the site of the former Building 20, demolished in 1998. Building 20 had been erected hastily during World War II as a temporary building to house the historic [[Radiation Laboratory at the Massachusetts Institute of Technology|Radiation Laboratory]]. Over the course of 55 years, its \"temporary\" nature allowed research groups to have more space, and to make more creative use of that space, than was possible in more respectable buildings. The building also provided permanent rooms for official Institute clubs and groups, including the [[Tech Model Railroad Club]] and the MIT Electronic Research Society (MITERS).\\n\\nProfessor [[Jerome Lettvin|Jerome Y. Lettvin]] once quipped, \"You might regard it as the womb of the Institute. It is kind of messy, but by God it is procreative!\"'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Функция формирования запроса к chatGPT по пользовательскому вопросу и базе знаний\n",
        "def query_message(\n",
        "    query: str, # пользовательский запрос\n",
        "    df: pd.DataFrame, # DataFrame со столбцами text и embedding (база знаний)\n",
        "    model: str, # модель\n",
        "    token_budget: int # ограничение на число отсылаемых токенов в модель\n",
        ") -> str:\n",
        "    \"\"\"Возвращает сообщение для GPT с соответствующими исходными текстами, извлеченными из фрейма данных (базы знаний).\"\"\"\n",
        "    strings, relatednesses = strings_ranked_by_relatedness(query, df) # функция ранжирования базы знаний по пользовательскому запросу\n",
        "    # Шаблон инструкции для chatGPT\n",
        "    message = 'Use the articles about MIT below to answer the following question. If you couldn’t find the answer in the articles, write “Couldn’t find the answer.”'\n",
        "    # Шаблон для вопроса\n",
        "    question = f\"\\n\\nQuestion: {query}\"\n",
        "\n",
        "    # Добавляем к сообщению для chatGPT релевантные строки из базы знаний, пока не выйдем за допустимое число токенов\n",
        "    for string in strings:\n",
        "        next_article = f'\\n\\nWikipedia article section:\\n\"\"\"\\n{string}\\n\"\"\"'\n",
        "        if (num_tokens(message + next_article + question, model=model) > token_budget):\n",
        "            break\n",
        "        else:\n",
        "            message += next_article\n",
        "    return message + question\n",
        "\n",
        "def ask(\n",
        "    query: str, # пользовательский запрос\n",
        "    df: pd.DataFrame = df, # DataFrame со столбцами text и embedding (база знаний)\n",
        "    model: str = GPT_MODEL, # модель\n",
        "    token_budget: int = 4096 - 500, # ограничение на число отсылаемых токенов в модель\n",
        "    print_message: bool = False, # нужно ли выводить сообщение перед отправкой\n",
        ") -> str:\n",
        "    \"\"\"Отвечает на вопрос, используя GPT и базу знаний.\"\"\"\n",
        "    # Формируем сообщение к chatGPT (функция выше)\n",
        "    message = query_message(query, df, model=model, token_budget=token_budget)\n",
        "    # Если параметр True, то выводим сообщение\n",
        "    if print_message:\n",
        "        print(message)\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"You answer questions about MIT.\"},\n",
        "        {\"role\": \"user\", \"content\": message},\n",
        "    ]\n",
        "    response = openai.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=0 # гиперпараметр степени случайности при генерации текста. Влияет на то, как модель выбирает следующее слово в последовательности.\n",
        "    )\n",
        "    response_message = response.choices[0].message.content\n",
        "    return response_message"
      ],
      "metadata": {
        "id": "c9fLjsh4lPBZ"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Настройки бота\n",
        "logging.basicConfig(level=logging.ERROR)\n",
        "API_TOKEN = <TELEGRAMM TOKEN>\n",
        "bot = Bot(token=API_TOKEN)\n",
        "dp = Dispatcher()"
      ],
      "metadata": {
        "id": "vD2iBg8432Uj"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Хэндлеры\n",
        "@dp.message(Command(\"start\"))\n",
        "async def cmd_start(message: types.Message):\n",
        "\n",
        "    name = message.from_user.first_name\n",
        "    await message.answer(\"👋\")\n",
        "    time.sleep(2)\n",
        "    await message.answer(f\"Привет, {name} !\")\n",
        "    time.sleep(2)\n",
        "    await message.answer(\"Я бот. У меня под 'под капотом' GPT-3.5 Turbo!\")\n",
        "    time.sleep(2)\n",
        "    await message.answer(\"Для получения информации набери '/help' \")\n",
        "\n",
        "@dp.message(Command(\"help\"))\n",
        "async def cmd_start(message: types.Message):\n",
        "    await message.answer(\"Я отвечу на твои вопросы про 'Массачусетский технологический институт'\")\n",
        "    time.sleep(2)\n",
        "    await message.answer(\"В моей базе знаний 2773 записей\")\n",
        "    time.sleep(2)\n",
        "    await message.answer(\"Вот пример запроса к моей базе:\")\n",
        "    time.sleep(2)\n",
        "    await message.answer(\"What disciplines are taught in MIT?\")\n",
        "    time.sleep(2)\n",
        "    await message.answer(\"⬇️⬇️⬇️ Задай вопрос ⬇️⬇️⬇️\")\n",
        "\n",
        "@dp.message()\n",
        "async def cmd_start(message: types.Message):\n",
        "    txt = message.text\n",
        "    await message.answer(ask(str(txt)))"
      ],
      "metadata": {
        "id": "aDQUiJ-9ybJh"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Поллинг\n",
        "async def main():\n",
        "    await dp.start_polling(bot)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    asyncio.run(main())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PlCJu0RCiKqI",
        "outputId": "19b17127-6c81-46c3-e165-8251d75121db"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:aiogram.dispatcher:Received SIGINT signal\n"
          ]
        }
      ]
    }
  ]
}