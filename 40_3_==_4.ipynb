{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN4bQQRNks9TNVL7Op4p5TA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Maxxx-VS/The-Founder/blob/master/40_3_%3D%3D_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Дообучи русскоязычную модель GPT для генерации фейковых новостей.\n",
        "2. Датасет необходимо найти самостоятельно.\n",
        "3. Приведи 5-10 примеров сгенерированных фейковых новостей на русском языке.\n",
        "4. Подбери параметры генерации, улучшите качество новостей.\n",
        "5. Изучи model.generate более детально.\n",
        "6. Добейся такой генерации, чтобы не было обрыва мысли, новость заканчивалась либо точкой, либо восклицательным знаком, либо вопросительным (если уместно).\n",
        "\n"
      ],
      "metadata": {
        "id": "qhi0RgoR73tC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tHM-ajR770TE"
      },
      "outputs": [],
      "source": [
        "# Импортируем необходимые библиотеки\n",
        "from transformers import TextDataset, DataCollatorForLanguageModeling, Trainer, TrainingArguments\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "import torch\n",
        "DEVICE = torch.device(\"cuda:0\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Определяем GPT модель и токенизатор\n",
        "model_name = \"sberbank-ai/rugpt3medium_based_on_gpt2\"\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name).to(DEVICE)"
      ],
      "metadata": {
        "id": "H0VTw9j38SbQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Загружаем и создаем датасет\n",
        "train_path = 'train_dataset.txt'\n",
        "train_dataset = TextDataset(tokenizer=tokenizer, file_path=train_path, block_size=64)\n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
      ],
      "metadata": {
        "id": "jZSyk9TZ8i7g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Параметры для обучения\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./finetuned\",       # директория с выходными данными\n",
        "    overwrite_output_dir=True,      # перезаписываем содержимое выходной директории при каждом запуске\n",
        "    num_train_epochs=200,           # число эпох обучения\n",
        "    per_device_train_batch_size=32, # batch size для обучения\n",
        "    per_device_eval_batch_size=32,  # batch size для выполнения\n",
        "    warmup_steps=10,                # количество шагов для \"прогрева\" (управление скоростью обучения)\n",
        "    gradient_accumulation_steps=16,) # накопление градиента (16 шагов накапливаем градиенты для batch_size, эмуляция вычисления на пакете 16 * 32 для слабых GPU)\n",
        "\n",
        "# Инициализируем класс обучения\n",
        "trainer = Trainer(\n",
        "    model=model,                 # модель\n",
        "    args=training_args,          # параметры обучения\n",
        "    data_collator=data_collator, # загрузчик данных\n",
        "    train_dataset=train_dataset, # датасет для обучения\n",
        "    optimizers = (torch.optim.AdamW(model.parameters(), lr=1e-5), None)) # оптимизатор"
      ],
      "metadata": {
        "id": "KzDppOOt8xSE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Запуск обучения\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "TdqTOgGD9KeP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "text = \"Почему GPT так жестока?\\nМожет просто она - человек?\"\n",
        "input_ids = tokenizer.encode(text, return_tensors=\"pt\").to(DEVICE)\n",
        "model.eval()\n",
        "print()"
      ],
      "metadata": {
        "id": "VlnE5Btv9MC1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}